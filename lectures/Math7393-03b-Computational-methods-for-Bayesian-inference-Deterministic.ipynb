{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Computational methods for Bayesian inference\n",
        "\n",
        "Joshua French\n",
        "\n",
        "To open this information in an interactive Colab notebook, click the Open in Colab graphic below.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/jfrench/BayesianStatistics/blob/master/lectures/Math7393-03b-Computational-methods-for-Bayesian-inference-Deterministic.ipynb\"> <img src=\"https://colab.research.google.com/assets/colab-badge.svg\"> </a>\n",
        "\n",
        "------------------------------------------------------------------------"
      ],
      "id": "835fa1b0-48fa-4320-8137-a99d12c7597f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check to see if necessary packages are installed\n",
        "if(!require(mvtnorm, quietly = TRUE)) {\n",
        "  # install and load packages if necessary\n",
        "  install.packages(\"mvtnorm\", repos = \"https://cran.rstudio.com/\")\n",
        "  library(mvtnorm)\n",
        "}\n",
        "if(!require(cubature, quietly = TRUE)) {\n",
        "  install.packages(\"cubature\", repos = \"https://cran.rstudio.com/\")\n",
        "  library(cubature)\n",
        "}"
      ],
      "id": "d134d317-780a-49a6-b8fe-088dfbd36918"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deterministic methods\n",
        "\n",
        "## MAP estimation\n",
        "\n",
        "The *maximum a posteriori* estimator, $\\hat{\\theta}_{\\textrm{MAP}}$, summarizes the posterior with the parameter values that maximize the posterior distribution, i.e., $$\\hat{\\theta}_{\\textrm{MAP}} = \\text{argmax}_{\\theta} \\ln p(\\theta \\mid y) = \\text{argmax}_{\\theta} \\ln p(y \\mid \\theta ) + \\ln p(\\theta).$$\n",
        "\n",
        "**MAP Example 1**\n",
        "\n",
        "*Data distribution*\n",
        "\n",
        "$y_1, \\ldots, y_n \\mid \\theta \\stackrel{i.i.d.}{\\sim} \\text{Poisson}(\\theta)$\n",
        "\n",
        "pdf:\n",
        "\n",
        "<br>  \n",
        "<br>\n",
        "\n",
        "*Prior distribution*\n",
        "\n",
        "$\\theta \\sim \\text{Exp}(1)$\n",
        "\n",
        "pdf:\n",
        "\n",
        "<br>  \n",
        "<br>\n",
        "\n",
        "*Posterior distribution*\n",
        "\n",
        "pdf:\n",
        "\n",
        "<br>  \n",
        "<br>\n",
        "\n",
        "$\\ln p(\\theta \\mid y) \\propto \\text{const} - (n - 1) \\theta + \\sum y_i \\ln(\\theta)$\n",
        "\n",
        "Let’s start by generating some data."
      ],
      "id": "ad540b24-aef5-4275-b022-ae60a220e392"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate some synthetic data from a Poisson(0.5)\n",
        "set.seed(8)\n",
        "y <- rpois(10, lambda = 0.5)"
      ],
      "id": "ab5beea2-f0ed-4ecf-8022-612cecbeee35"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we create a function to compute the log of the unnormalized posterior."
      ],
      "id": "3e5b68c0-0c5a-4ede-91fe-731d156011c0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create function for log unnormalized posterior\n",
        "# theta = estimand\n",
        "# sumy = sum(y)\n",
        "# n = sample size\n",
        "lup <- function(theta, sumy, n) {\n",
        "  -(n + 1) * theta + sumy * log(theta)\n",
        "}"
      ],
      "id": "1ac96d0c-bf81-48bd-b66e-f591d3f69064"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now use the `optimize` function to optimize the objective function, `lup`, between 0 and 1.\n",
        "\n",
        "-   We start our search `interval` just above 0 to avoid numerical issues.\n",
        "-   We set `maximum` to `TRUE` to find the parameter that maximizes the objection function, `lup`."
      ],
      "id": "7e9b48ac-15f8-42eb-b905-c1c55e43cc5c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(map <- optimize(\n",
        "  f = lup, interval = c(0.0001, 10),\n",
        "  maximum = TRUE,\n",
        "  sumy = sum(y), n = length(y)\n",
        "))\n",
        "# maximum occurs at theta = 0.64"
      ],
      "id": "a1c4e2a4-0bea-4a0e-8efe-fd79cf9f16c5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot our results to double-check accuracy."
      ],
      "id": "bac893cb-776a-42ed-b14c-e7978f3a06b2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# domain of plot\n",
        "mytheta <- seq(0.0001, 1, length = 1000)\n",
        "# plot function\n",
        "plot(mytheta, lup(mytheta, sumy = sum(y), n = length(y)),\n",
        "  type = \"l\",\n",
        "  xlab = \"theta\", ylab = \"propto log posterior\"\n",
        ")\n",
        "# show maximum\n",
        "abline(v = map$maximum)"
      ],
      "id": "a9b022c0-d487-4007-9f10-47bca52a2ecd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now use a different approach that doesn’t simplify ahead of time. Note that\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\ln [p(y\\mid \\theta)p(\\theta)] &= \\ln p(y\\mid \\theta) + \\ln p(\\theta) \\\\\n",
        "&= \\ln \\left(\\prod_{i=1}^n p(y_i\\mid\\theta)\\right) + \\ln p(\\theta) \\\\\n",
        "&= \\sum_{i=1}^n \\ln p(y_i\\mid\\theta) + \\ln p(\\theta).\n",
        "\\end{aligned}\n",
        "$$"
      ],
      "id": "a7f1bc0d-89e6-4b8c-b4c6-29cdca0bcb0e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# second version of log unnormalized posterior\n",
        "lup2 <- function(theta, y) {\n",
        "  sum(dpois(y, lambda = theta, log = TRUE)) +\n",
        "    dexp(theta, rate = 1, log = TRUE)\n",
        "}\n",
        "\n",
        "# same results!\n",
        "optimize(\n",
        "  f = lup2, interval = c(0.0001, 10), maximum = TRUE,\n",
        "  y = y\n",
        ")"
      ],
      "id": "020dc1ea-efac-4e74-82ee-5977d383488b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**MAP Example 2 (2 parameter)**\n",
        "\n",
        "*Data distribution*\n",
        "\n",
        "$y_1, ..., y_n \\mid \\mu, \\sigma^2 \\stackrel{i.i.d.}{\\sim} N(\\mu, \\sigma^2)$\n",
        "\n",
        "pdf:\n",
        "\n",
        "<br>  \n",
        "<br>\n",
        "\n",
        "*Prior distribution*\n",
        "\n",
        "$\\mu \\sim U(10, 15)$\n",
        "\n",
        "pdf:\n",
        "\n",
        "<br>  \n",
        "<br>\n",
        "\n",
        "$p(\\sigma^2) \\propto N(0.5, 0.5^2) I_{(0,\\infty)}(\\sigma^2)$\n",
        "\n",
        "pdf:\n",
        "\n",
        "<br>  \n",
        "<br>\n",
        "\n",
        "This is essentially a truncated normal with a different scaling constant.\n",
        "\n",
        "We start by generating some fake data."
      ],
      "id": "b4e948f8-1c33-43d9-919e-0e3b02403689"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate some synthetic data\n",
        "# Normal with mean 11 and sd = 0.47\n",
        "set.seed(7)\n",
        "y <- rnorm(10, mean = 11, sd = 0.47)"
      ],
      "id": "f5b1a3e0-4b70-45c8-8a13-4b62b5788faa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We program the negative log of the unnormalized posterior density.\n",
        "\n",
        "-   The function takes $\\theta = (\\mu, \\sigma^2)$.\n",
        "-   We *don’t* constrain $\\mu$ to be between 10 and 15 and $\\sigma^2$ to be positive only because we will do this constraint in our optimization.\n",
        "-   We multiply the log posterior by -1 so that instead of trying to maximize the log unnormalized posterior, we minimize the negative log unnormalized posterior."
      ],
      "id": "b34c5753-c0e9-4e00-8ef2-df31816fdb9c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nlup <- function(theta, y) {\n",
        "  mu <- theta[1]\n",
        "  sigma <- sqrt(theta[2])\n",
        "  obj <- sum(dnorm(y, mean = mu, sd = sigma, log = TRUE)) +\n",
        "    dunif(mu, 10, 15, log = TRUE) +\n",
        "    dnorm(sigma^2, mean = 0.5, sd = 0.5, log = TRUE)\n",
        "  -obj\n",
        "}"
      ],
      "id": "a76c6d77-7280-4af4-a992-480643dbd050"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now use the `optim` function to perform multi-dimensional optimization.\n",
        "\n",
        "-   `par`: vector of starting values\n",
        "-   `f`: function to MINIMIZE. The first argument must be the argument you want to optimize over.\n",
        "-   `lower`: the constraints on the lower bound\n",
        "-   `upper`: the constraints on the upper bound\n",
        "-   `method`: the optimization method. `\"L-BFGS-B\"` allows use to specify constraints.\n",
        "-   `control`: list of optional tuning parameters.\n",
        "-   The remaining arguments are the arguments that must be supplied to `f`."
      ],
      "id": "1fdda726-fe44-499b-b1ed-2bcd12924f31"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optim(\n",
        "  par = c(12.5, 1),\n",
        "  f = nlup,\n",
        "  lower = c(10.0001, 0.05),\n",
        "  upper = c(14.9999, 2),\n",
        "  method = \"L-BFGS-B\",\n",
        "  y = y\n",
        ")"
      ],
      "id": "c461e023-d242-46db-b7e1-7d9320eea686"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`nlminb` is an alternative optimizer that is more robust (from my personal experience.)\n",
        "\n",
        "-   The arguments are self-explanatory."
      ],
      "id": "df50813d-1d06-45e1-88d9-ac53f501671b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(map <- nlminb(\n",
        "  start = c(12.5, 1),\n",
        "  objective = nlup,\n",
        "  lower = c(10.0001, 0.0001),\n",
        "  upper = c(14.9999, 2),\n",
        "  y = y\n",
        "))"
      ],
      "id": "d4cd3b2f-31df-48a6-816e-c8e09b11d3ce"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s plot our results."
      ],
      "id": "fe96d907-2435-4664-9c32-bd396ea695f2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create sequence of values for mu and sigmasq\n",
        "mymu <- seq(10.8, 11.2, length = 200)\n",
        "mysigmasq <- seq(0.15, 0.45, length = 200)\n",
        "# create grid\n",
        "mytheta <- expand.grid(mymu, mysigmasq)\n",
        "# for each row of mytheta, plug it into nlup function\n",
        "z <- apply(mytheta, 1, function(theta) {\n",
        "  nlup(theta, y = y)\n",
        "})\n",
        "# convert z to matrix for plotting\n",
        "zmat <- matrix(z, nrow = length(mymu))\n",
        "# create heat map of objective surface\n",
        "image(mymu, mysigmasq, zmat,\n",
        "  col = hcl.colors(64, rev = TRUE),\n",
        "  xlab = expression(mu), ylab = expression(sigma^2)\n",
        ")\n",
        "# add contours\n",
        "contour(mymu, mysigmasq, zmat, add = TRUE)\n",
        "# place point for posterior mode\n",
        "points(map$par[1], map$par[2], pch = 20)\n",
        "title(\"log posterior density (unnormalized)\")"
      ],
      "id": "57be5776-bb42-46c8-a100-e53ef4a5d635"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cubature methods\n",
        "\n",
        "Cubature methods approximate an integral by evaluating a function at a finite number of points and aggregating the results. (We won’t discuss specifics.)\n",
        "\n",
        "**Cubature method example (Beta-Binomial)**\n",
        "\n",
        "*Data distribution*\n",
        "\n",
        "$y \\mid \\theta \\sim \\text{Bin}(n, \\theta)$.\n",
        "\n",
        "Let’s assume $n=980$ and $y=437$.\n",
        "\n",
        "*Prior distribution*\n",
        "\n",
        "$\\theta \\sim \\text{Beta}(\\alpha, \\beta)$.\n",
        "\n",
        "Let’s assume $\\alpha=\\beta=1$.\n",
        "\n",
        "*Posterior distribution*\n",
        "\n",
        "$\\theta \\mid y \\sim \\text{Beta}(y + \\alpha, n - y + \\beta)$.\n",
        "\n",
        "This has posterior mean $\\frac{y + \\alpha}{n + \\alpha + \\beta}$.\n",
        "\n",
        "Based on our assumptions above, $\\theta \\mid y \\sim \\text{Beta}(438, 544)$.\n",
        "\n",
        "*Posterior predictive distribution*\n",
        "\n",
        "$P(\\tilde{y} = 1 \\mid y) = \\frac{y + \\alpha}{n + \\alpha + \\beta}$.\n",
        "\n",
        "Based on previous assumptions, $P(\\tilde{y} = 1 \\mid y) = 448/(438 + 544) \\approx 0.446$.\n",
        "\n",
        "Let’s use the cubature method to approximate some of these.\n",
        "\n",
        "We start by defining the posterior density with a generic normalizing constant."
      ],
      "id": "5a5c95ec-5c90-4394-9959-1083afe0cd2c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# unnormalized posterior\n",
        "dpost <- function(theta, const = 1) {\n",
        "  dbinom(x = 437, size = 980, prob = theta) *\n",
        "    dbeta(theta, shape1 = 1, shape2 = 1) /\n",
        "    const\n",
        "}"
      ],
      "id": "9c37c7ad-85c4-4ea5-913e-97256c7130b9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We determine the normalizing constant."
      ],
      "id": "84535cf3-77d6-42d3-a60e-b7ba295b21dd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(nconst <- integrate(dpost, lower = 0, upper = 1)$value)"
      ],
      "id": "166cc8ac-02fc-45b2-a829-590948091e9b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we define the function $\\theta p(\\theta \\mid y)$."
      ],
      "id": "7c9ffd43-aee4-485c-8e3c-462faee8305c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# theta * posterior\n",
        "mean_target <- function(theta, const) {\n",
        "  theta * dpost(theta, const)\n",
        "}"
      ],
      "id": "026eb585-59bb-4820-bc80-f952edb82026"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We integrate $\\theta p(\\theta \\mid y)$ for $\\theta \\in [0, 1]$."
      ],
      "id": "6bd7fdd4-3397-4a8a-b7ce-2faaf429513f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute posterior mean using cubature\n",
        "integrate(mean_target, lower = 0, upper = 1, const = nconst)"
      ],
      "id": "ba79ee01-2d7e-4956-a091-2cb4b7cf421a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we define the function that evaluates $P(\\tilde{y} = 1 \\mid \\theta) p(\\theta \\mid y)$."
      ],
      "id": "3dc3bb8f-d62f-4095-af63-0fcad7f3dce3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pytilde * ptarget\n",
        "pytilde_target <- function(theta, const) {\n",
        "  dbinom(x = 1, size = 1, prob = theta) *\n",
        "    dpost(theta, const)\n",
        "}"
      ],
      "id": "8e6c25d0-b2ea-4478-88af-0ec9ed98dac5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lastly, we integrate that function to compute $P(\\tilde{y} = 1 \\mid \\theta)$."
      ],
      "id": "817b1198-a923-4a8c-9465-63704392b9f9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# posterior predictive probability\n",
        "integrate(pytilde_target, lower = 0, upper = 1, const = nconst)"
      ],
      "id": "03903818-e503-4c0a-92ba-cf424e59d4b4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bayesian CLT for $N(\\mu,\\sigma^2)$\n",
        "\n",
        "**Example 1**\n",
        "\n",
        "*Data distribution*\n",
        "\n",
        "$y_1, ..., y_n \\mid \\theta \\stackrel{i.i.d}{\\sim} \\text{Poisson}(\\theta)$\n",
        "\n",
        "*Prior distribution*\n",
        "\n",
        "$\\theta \\sim \\text{Exp}(1)$\n",
        "\n",
        "*Negative Hessian,* $-H(\\theta)$\n",
        "\n",
        "$-\\frac{d^2}{d\\theta^2} \\ln p(y \\mid \\theta) = \\frac{\\sum y_i}{\\theta^2}$.\n",
        "\n",
        "*Approximate posterior distribution*\n",
        "\n",
        "For a large sample of data, $p(\\theta \\mid y) \\approx N(\\hat{\\theta}, \\hat{\\theta}^2/\\sum y_i)$.\n",
        "\n",
        "We start be generating a small data set."
      ],
      "id": "1023b547-feec-43e0-b91b-956395cea4f1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate some synthetic data\n",
        "# Poisson with mean of 0.5\n",
        "set.seed(3) # for reproducibility\n",
        "y <- rpois(10, lambda = 0.5)"
      ],
      "id": "2e4cf13f-60d6-41d0-b976-5374c2b003fa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now define the posterior density with a generic normalizing constant."
      ],
      "id": "aebb9a32-69d0-472f-b2f5-aa3eef361ed2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dpost <- function(theta, y, const = 1) {\n",
        "  log_pdata <- sum(dpois(y, lambda = theta, log = TRUE))\n",
        "  log_pprior <- dexp(theta, rate = 1, log = TRUE)\n",
        "  exp(log_pdata + log_pprior - log(const))\n",
        "}"
      ],
      "id": "06a68720-ed18-4c11-a7aa-df03fb74f52d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s try plotting this function to help us determine what we should be maximizing over."
      ],
      "id": "62855e6f-9e5e-494f-b0c0-24012f990ff0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot dpost to determine what to maximize over\n",
        "x <- seq(0.001, 10, len = 1000)\n",
        "plot(x, dpost(theta = x, y = y), type = \"l\", )"
      ],
      "id": "dd0795dc-cc0d-4e15-a208-0adeffbba4a0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We’re getting weird results because `dpost` is trying to evaluate `dpois` with a vector `y` and a vector `theta` whose dimensions are incompatible.\n",
        "\n",
        "We want to evaluate `dpois(y, ...)` for *each* value of `theta`.\n",
        "\n",
        "We can use the `Vectorize` function to vectorize a function with respect to a certain argument."
      ],
      "id": "9f6071b9-930e-41c6-8ea1-9f5acf3d08f3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vdpost <- Vectorize(dpost, vectorize.args = \"theta\")"
      ],
      "id": "61689c5b-0f45-47ac-828e-bdff1763d7e9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we try our plot again."
      ],
      "id": "eff8fb20-d1d4-4ccc-a4a6-b71b2661328c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot vectorized dpost to determine what to maximize over\n",
        "plot(x, vdpost(theta = x, y = y), type = \"l\",\n",
        "     ylab = \"unnormalized density\")"
      ],
      "id": "01eff5e3-8fc4-4274-8a88-982c35f929da"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can determine $\\hat{\\theta}_{\\text{MAP}}$ over the interval $[0, 2]$."
      ],
      "id": "46617f82-b33f-448d-ac48-dda66e37be6e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# determine MAP\n",
        "(map <- optimize(vdpost, interval = c(0, 2), y = y, maximum = TRUE)$maximum)"
      ],
      "id": "b33ea79e-e702-4b73-a03e-40dc2cf2d9f0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$\\hat{\\theta}_{MAP}\\approx 0.18$. Thus, our posterior approximation is $N(0.18, 0.18^2/\\sum y_i)$.\n",
        "\n",
        "Let’s plot the “truth” versus the approximation. In order to do that, we need to figure out the “true” distribution. We do this to illustrate the effectiveness of the approximation. We wouldn’t normally do this.\n",
        "\n",
        "We find our normalizing constant."
      ],
      "id": "97803fdf-d977-46bb-938c-1d500b923afa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# determine normalizing constant\n",
        "(nconst <- integrate(f = vdpost, lower = 0, upper = 10, y = y)$value)"
      ],
      "id": "36e38cda-c837-493b-86b2-7dfc54a5cd03"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We double-check that the posterior is proper!"
      ],
      "id": "3f1e6585-d907-4423-a541-cf24db194f93"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "integrate(vdpost, lower = 0, upper = 10, y = y, const = nconst)"
      ],
      "id": "8db278c3-4b70-45c3-9120-28f0a1f1db1e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define a function to evaluate our approximate posterior distribution."
      ],
      "id": "e105a54f-118c-4966-929a-a87cd46836ec"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# normal approximation posterior\n",
        "dpapprox <- function(theta, y, thetahat) {\n",
        "  dnorm(theta, mean = thetahat, sd = sqrt(thetahat^2 / sum(y)))\n",
        "}"
      ],
      "id": "baac5405-442d-42cf-be82-e9064f0abb01"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we plot the “true” posterior density versus the approximate posterior density."
      ],
      "id": "6a63a649-1a15-47c9-90ec-f577c92a518b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# range of theta values\n",
        "theta <- seq(0, 2, length = 1000)\n",
        "# plot true density\n",
        "plot(theta, vdpost(theta, y, nconst),\n",
        "     ylab = \"density\", type = \"l\", col = \"orange\")\n",
        "# plot normal approximation\n",
        "lines(theta, dpapprox(theta, y, thetahat = map),\n",
        "      col = \"blue\")\n",
        "legend(\"topright\",\n",
        "  legend = c(\"truth\", \"approximation\"),\n",
        "  col = c(\"orange\", \"blue\"), lty = 1\n",
        ")"
      ],
      "id": "d9468a99-5e73-4c5c-90f6-eb07106e68f2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our approximation isn’t great because our sample size is small. Let’s perform the same approximation with a larger sample size.\n",
        "\n",
        "We generate 100 i.i.d. observations from a Poisson(0.5) distribution."
      ],
      "id": "fa2dbf90-24fe-4a8b-b400-5305b022891a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set.seed(3) # for reproducibility\n",
        "y100 <- rpois(100, lambda = 0.5)"
      ],
      "id": "850f66a3-477d-4dc8-a4a7-a71770da2232"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We once again plot the unnormalized posterior to determine the range of `theta` to optimize over."
      ],
      "id": "c1201382-fc55-49b2-983d-3c6325b27a55"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot(x, vdpost(theta = x, y = y100),\n",
        "  type = \"l\",\n",
        "  xlab = \"theta\", ylab = \"unnormalized density\"\n",
        ")"
      ],
      "id": "a740ec34-df7d-426e-ad75-bc3e787eff17"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We determine $\\hat{\\theta}_{\\text{MAP}}$."
      ],
      "id": "d9951867-a4d2-462f-99d1-84efdf451531"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(map100 <- optimize(vdpost, interval = c(0, 2),\n",
        "                    y = y100, maximum = TRUE)$maximum)"
      ],
      "id": "2148351a-2d78-4381-aaed-cbabfb7e96b3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$\\hat{\\theta}_{\\text{MAP}}\\approx 0.42$. Thus, our posterior approximation is $N(0.42, 0.42^2/\\sum y_i)$.\n",
        "\n",
        "Let’s plot the “truth” versus the approximation.\n",
        "\n",
        "We compute the normalizing constant for our posterior."
      ],
      "id": "a7390e1e-3cd8-4f13-9038-4b887348af4c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# determine normalizing constant\n",
        "(nconst100 <- integrate(f = vdpost, lower = 0, upper = 10, y = y100)$value)"
      ],
      "id": "d9067cde-70de-4ecc-96ee-7554b05ad5ac"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We double-check that posterior is proper."
      ],
      "id": "5e239291-d127-4c4a-836a-e4a6fa154c5b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "integrate(vdpost, lower = 0, upper = 10, y = y100, const = nconst100)"
      ],
      "id": "1226c9bd-2a79-43e4-b956-246b945731f2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have a big issue! Our (numerical) integral is no longer integrating to 1. Why? Computational underflow!\n",
        "\n",
        "When we evaluate our unnormalized posterior, all of the values are close to zero.\n",
        "\n",
        "We need to shift the unnormalized posterior vertically so that some of the values are higher. I choose to make the largest value 1 by using the trick below.\n",
        "\n",
        "-   Evaluate the log unnormalized density over the range of the $\\theta$.\n",
        "-   Subtract the LARGEST number you get from the log unnormalized density.\n",
        "-   Convert back to the original scale using $\\exp$."
      ],
      "id": "9ff4c1d8-0fd8-488a-a6be-6631859469d3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lqpost <- function(theta, y) {\n",
        "  log_pdata <- sum(dpois(y, lambda = theta, log = TRUE))\n",
        "  log_pprior <- dexp(theta, rate = 1, log = TRUE)\n",
        "  log_pdata + log_pprior\n",
        "}\n",
        "vlqpost <- Vectorize(lqpost, vectorize.args = \"theta\")\n",
        "range(vlqpost(x, y = y100))"
      ],
      "id": "7e83182b-04b1-4909-903a-409abfc3ba6f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a “robust” version of the unnormalized density."
      ],
      "id": "5f9fcf19-5056-42cd-afab-6ccfc462acdc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "qpost_robust <- function(theta, y) {\n",
        "  log_pdata <- sum(dpois(y, lambda = theta, log = TRUE))\n",
        "  log_pprior <- dexp(theta, rate = 1, log = TRUE)\n",
        "  exp(log_pdata + log_pprior + 84.11288)\n",
        "}\n",
        "# vectorize\n",
        "vqpost_robust <- Vectorize(qpost_robust,\n",
        "  vectorize.args = \"theta\"\n",
        ")"
      ],
      "id": "c4ba112d-adcd-483b-80d4-c964d5431b29"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The new unnormalized density has a maximum of 1."
      ],
      "id": "a5a6cb04-f543-4cb9-9221-191237b94a11"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot(x, vqpost_robust(x, y = y100),\n",
        "  xlab = \"theta\", ylab = \"unnormalized density\",\n",
        "  type = \"l\"\n",
        ")"
      ],
      "id": "dbdbe532-46d0-4ee4-8649-fd54b9c8299d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we determine the normalizing constant of our robust unnormalized density."
      ],
      "id": "97ff84f8-97c5-40f1-a24a-5f58f9dd65d3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# determine normalizing constant\n",
        "(nconst100 <- integrate(f = vqpost_robust, lower = 0, upper = 10, y = y100)$value)"
      ],
      "id": "8056fee0-f012-451a-b8a6-3f7c23486093"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now create a robust version of our posterior density."
      ],
      "id": "d939e054-3867-4566-9a4f-baf456e39b02"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# posterior density function\n",
        "dpost_robust <- function(theta, y, const) {\n",
        "  qpost_robust(theta, y) / const\n",
        "}\n",
        "# vectorized version of dpost_robust for integrate function\n",
        "vdpost_robust <- Vectorize(dpost_robust,\n",
        "  vectorize.args = \"theta\"\n",
        ")"
      ],
      "id": "b94bd25d-c23c-48d5-8c8c-59752b9d7cd5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We double-check that our robust posterior density is proper."
      ],
      "id": "96ad7d36-4919-44c9-b069-1c77d259d8ee"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "integrate(vdpost_robust,\n",
        "  lower = 0, upper = 10,\n",
        "  y = y100, const = nconst100\n",
        ")"
      ],
      "id": "705b3bff-6fa1-4420-a427-b2ecaa7d0a71"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we create a plots to compare our true density versus our normal approximation."
      ],
      "id": "2e1d6416-f503-4990-96bc-371967f98896"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot true density\n",
        "plot(theta, vdpost_robust(theta, y100, nconst100),\n",
        "     ylab = \"density\", type = \"l\", col = \"orange\")\n",
        "# plot normal approximation\n",
        "lines(theta, dpapprox(theta, y100, thetahat = map100), col = \"blue\")\n",
        "legend(\"topright\",\n",
        "  legend = c(\"truth\", \"approximation\"),\n",
        "  col = c(\"orange\", \"blue\"), lty = 1\n",
        ")"
      ],
      "id": "af67f520-6e61-447b-807c-d5f3aa1f3e06"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Bayesian CLT Example (Two parameter)**\n",
        "\n",
        "*Data distribution*\n",
        "\n",
        "$y_1, y_2, \\ldots, y_n \\mid \\mu, \\sigma^2 \\stackrel{i.i.d.}{\\sim} N(\\mu, \\sigma^2)$\n",
        "\n",
        "*Prior distribution*\n",
        "\n",
        "$\\mu \\sim U(10, 15)$, $p(\\sigma^2) \\propto N(0.5, 0.5^2) I_{(0, \\infty)}(\\sigma^2)$\n",
        "\n",
        "*Posterior distribution (Bayesian CLT)*\n",
        "\n",
        "Assuming $n$ is large, $\\theta = (\\mu, \\sigma^2)$, and $\\hat{\\theta} = \\hat{\\theta}_{MAP}$, $\\theta \\mid y \\sim N(\\hat{\\theta}, I(\\hat{\\theta})^{-1}).$\n",
        "\n",
        "Let’s determine $I(\\hat{\\theta})^{-1}$.\n",
        "\n",
        "</br>  \n",
        "</br>  \n",
        "</br>  \n",
        "</br>  \n",
        "</br>  \n",
        "</br>  \n",
        "</br>  \n",
        "</br>  \n",
        "</br>  \n",
        "</br>  \n",
        "</br>  \n",
        "</br>  \n",
        "</br>  \n",
        "</br>  \n",
        "</br>  \n",
        "</br>  \n",
        "</br>  \n",
        "</br>  \n",
        "</br>  \n",
        "</br>  \n",
        "</br>\n",
        "\n",
        "Let’s generate some data."
      ],
      "id": "060f61d4-013e-4937-b1a0-feb969f7efaa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate some synthetic data\n",
        "# in practice, we just have some data\n",
        "set.seed(7)\n",
        "y <- rnorm(100, mean = 11, sd = 0.47)"
      ],
      "id": "5bd76995-1949-46a8-af35-1afce76c8e64"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we create functions related to the true posterior density. This wouldn’t normally be needed, but we want to assess how good our approximation is.\n",
        "\n",
        "We create a density function with a built-in correction to address the numerical underflow issue. The function takes:\n",
        "\n",
        "-   `theta`: a vector parameterized as $\\theta = (\\mu, \\sigma^2)$.\n",
        "-   `y`: data vector.\n",
        "-   `const`: the normalizing constant, which we don’t yet know. We use 1."
      ],
      "id": "e072bc62-373c-4bbf-9c43-8c288e3ed5bc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dpost <- function(theta, y, const = 1) {\n",
        "  mu <- theta[1]\n",
        "  sigma <- sqrt(theta[2])\n",
        "  log_pdata <- sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))\n",
        "  log_pmu <- dunif(mu, 10, 15, log = TRUE)\n",
        "  log_psigmasq <- dnorm(sigma^2, mean = 0.5, sd = 0.5, log = TRUE)\n",
        "  log_qtheta <- log_pdata + log_pmu + log_psigmasq\n",
        "  exp(log_qtheta + 70)/const\n",
        "}"
      ],
      "id": "d0777e4a-a0b6-4df9-be0f-06510f710b8c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We determine the normalizing constant over the interval $\\mu \\in [10, 15]$ and $\\sigma^2\\in[0, 2]$."
      ],
      "id": "9596536e-e187-4660-95ce-01d4e284ddcd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(const <- cubintegrate(\n",
        "  f = dpost,\n",
        "  lower = c(10, 0),\n",
        "  upper = c(15, 2),\n",
        "  y = y\n",
        ")$integral)"
      ],
      "id": "2cc856c9-baec-4a2f-9ffb-1784c3364c19"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let’s determine our MAP estimate.\n",
        "\n",
        "We first define a function to evaluate the log unnormalized posterior."
      ],
      "id": "58e5c1d0-14e1-4df3-b0bd-baed1f744fdb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_qtheta <- function(theta, y) {\n",
        "  mu <- theta[1]\n",
        "  sigma <- sqrt(theta[2])\n",
        "  log_pdata <- sum(dnorm(y, mean = mu, sd = sigma, log = TRUE))\n",
        "  log_pmu <- dunif(mu, 10, 15, log = TRUE)\n",
        "  log_psigmasq <- dnorm(sigma^2, mean = 0.5, sd = 0.5, log = TRUE)\n",
        "  log_pdata + log_pmu + log_psigmasq\n",
        "}"
      ],
      "id": "66ebacff-67af-4841-ba67-d23085895d84"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now use the `optim` function to maximize the objective function.\n",
        "\n",
        "-   We use `fnscale = -1` to make `optim` perform maximization instead of minimization"
      ],
      "id": "db9a4028-8758-4a8d-b478-8705598ebd8b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(map <- optim(\n",
        "  par = c(12.5, 1),\n",
        "  f = log_qtheta,\n",
        "  lower = c(10.0001, 0.05),\n",
        "  upper = c(14.9999, 2),\n",
        "  method = \"L-BFGS-B\",\n",
        "  y = y,\n",
        "  control = list(fnscale = -1)\n",
        "))"
      ],
      "id": "a578701b-6b39-4ff7-a0a2-f208e9435591"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we build a function that returns the inverse of the observation information matrix."
      ],
      "id": "e7c7a1c3-0bbb-43ec-aa96-07508ad442a2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# return the inverse of the observed information matrix\n",
        "inv_ihat <- function(thetahat, n) {\n",
        "  mu <- thetahat[1]\n",
        "  sigma <- sqrt(thetahat[2])\n",
        "  # 2nd derivative of log likelihood w/r to mu\n",
        "  d2dmu2 <- -n / sigma^2\n",
        "  # derivative of log likelihood w/r to mu and sigmasq\n",
        "  d2dmudsigmasq <- -sum((y - mu)) / sigma^4\n",
        "  # 2nd derivative of log likelihood w/r to sigmasq\n",
        "  d2dsigmasq2 <- n / (2 * sigma^4) - 1 / sigma^6 * sum((y - mu)^2)\n",
        "  #\n",
        "  H <- cbind(c(d2dmu2, d2dmudsigmasq), c(d2dmudsigmasq, d2dsigmasq2))\n",
        "  solve(-H)\n",
        "}"
      ],
      "id": "7e91b531-78f9-40a7-8e8b-9256fe9d8f1e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we create a function that evaluates the bivariate normal approximation of the true density with respect to $\\theta$."
      ],
      "id": "3c4f11b8-53ae-424e-b4c0-4e07d4cfed3b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# posterior approximation\n",
        "dpapprox <- function(theta, thetahat, vhat) {\n",
        "  mvtnorm::dmvnorm(x = theta, mean = thetahat, sigma = vhat)\n",
        "}"
      ],
      "id": "ecd019bb-905b-42e0-8960-7f6d16db376f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we visually compare the results."
      ],
      "id": "fb6f91bc-0fcf-4836-b8bc-d31b4eb115d6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create sequence of values for mu and sigmasq\n",
        "mymu <- seq(10.95, 11.2, length = 200)\n",
        "mysigmasq <- seq(0.14, 0.29, length = 200)\n",
        "# create grid\n",
        "mytheta <- expand.grid(mymu, mysigmasq)\n",
        "\n",
        "# for each row of mytheta, plug it into dpost function\n",
        "z <- apply(mytheta, 1, function(theta) {\n",
        "  dpost(theta, y = y, const = const)\n",
        "})\n",
        "\n",
        "# convert z to matrix for plotting\n",
        "zmat <- matrix(z, nrow = length(mymu))\n",
        "\n",
        "# compute observed Information outside of loop\n",
        "vhat <- inv_ihat(map$par, length(y))\n",
        "zhat <- mvtnorm::dmvnorm(\n",
        "  x = mytheta,\n",
        "  mean = map$par,\n",
        "  sigma = vhat\n",
        ")\n",
        "# convert z to matrix for plotting\n",
        "zhatmat <- matrix(zhat, nrow = length(mymu))\n",
        "\n",
        "# side-by-side results\n",
        "par(mfrow = c(1, 2))\n",
        "\n",
        "# create heat map of objective surface\n",
        "image(mymu, mysigmasq, zmat,\n",
        "  col = hcl.colors(64, rev = TRUE),\n",
        "  xlab = expression(mu),\n",
        "  ylab = expression(sigma^2),\n",
        "  zlim = range(c(z, zhat))\n",
        ")\n",
        "# add contours\n",
        "contour(mymu, mysigmasq, zmat,\n",
        "  add = TRUE\n",
        ")\n",
        "title(\"true posterior\")\n",
        "\n",
        "# create heat map of approximation surface\n",
        "image(mymu, mysigmasq, zhatmat,\n",
        "  col = hcl.colors(64, rev = TRUE),\n",
        "  xlab = expression(mu),\n",
        "  ylab = expression(sigma^2),\n",
        "  zlim = c(range(c(z, zhat)))\n",
        ")\n",
        "# add contours\n",
        "contour(mymu, mysigmasq, zhatmat, add = TRUE)\n",
        "title(\"normal approximation\")"
      ],
      "id": "8c51b80e-11f7-4b24-a319-4c648155a519"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "ir",
      "display_name": "R",
      "language": "R"
    }
  }
}